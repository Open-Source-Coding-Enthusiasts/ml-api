{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x26394afc0d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "# Replace the following values with your actual database\n",
    "username = 'postgres'\n",
    "password = 'ffzhzicfpkpsbljjdsdwlawqdklenfsfzchtknhpwkpndyzoxq'\n",
    "host = 'srv17.mikr.us'\n",
    "port = '30165'  # Changed to match the port Docker is listening on\n",
    "database = 'postgres'\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "os.environ['DB_CONNECTION_STRING'] = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'http://10.147.18.38:31216'\n",
    "# Now you can use `engine` to interact with your database\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cena', 'Marka pojazdu', 'Model pojazdu', 'Wersja', 'Generacja',\n",
       "       'Rok produkcji', 'Przebieg', 'Pojemność skokowa', 'Rodzaj paliwa',\n",
       "       'Moc', 'Skrzynia biegów', 'Napęd', 'Spalanie Poza Miastem',\n",
       "       'Spalanie W Mieście', 'Typ nadwozia', 'Emisja CO2', 'Liczba drzwi',\n",
       "       'Liczba miejsc', 'Kolor', 'Rodzaj koloru', 'Kraj pochodzenia',\n",
       "       'Zarejestrowany w Polsce', ' Pierwszy właściciel (od nowości)',\n",
       "       'Bezwypadkowy', 'Serwisowany w ASO', 'Stan',\n",
       "       'Data pierwszej rejestracji w historii pojazdu',\n",
       "       'Numer rejestracyjny pojazdu', 'Wyświetl VIN', 'Tuning', 'Leasing',\n",
       "       'Opłata początkowa', 'Miesięczna rata', 'Liczba pozostałych rat',\n",
       "       'Wartość wykupu', 'Spalanie W Cyklu Mieszanym',\n",
       "       'Możliwość finansowania', 'Faktura VAT', 'lub do (przebieg km)',\n",
       "       'Uszkodzony', 'VAT marża', 'Kierownica po prawej (Anglik)', 'Autonomia',\n",
       "       'Średnie zużycie', 'Rodzaj własności baterii'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_table('otomoto_data', engine).drop(columns=['index','Oblicz','Kup ten pojazd na ratyOblicz','Pokaż oferty z numerem VIN','Oferta od','Ma numer rejestracyjny'])\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Cena', 'Marka pojazdu', 'Model pojazdu', 'Wersja', 'Generacja',\n",
    "'Rok produkcji', 'Przebieg', 'Pojemność skokowa', 'Rodzaj paliwa',\n",
    "'Moc', 'Skrzynia biegów', 'Napęd', 'Spalanie W Mieście', 'Typ nadwozia','Liczba drzwi',\n",
    "'Liczba miejsc', 'Kolor', 'Kraj pochodzenia','Stan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Price', 'Vehicle brand', 'Vehicle model', 'Vehicle Version', 'Vehicle Generation',\n",
    "'Year of production', 'Mileage', 'Engine Capacity', 'Fuel Type', 'Horse Power',\n",
    "'Transmission Type', 'Drive Type', 'Gas Usage per 100km', 'Car Body Type',\n",
    "'Number of doors', 'Number of seats', 'Color', 'Country of origin',\n",
    "'New/Used']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import Union\n",
    "from sqlalchemy import create_engine\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine(os.getenv('DB_CONNECTION_STRING'))\n",
    "        self.df = pd.read_sql_table('otomoto_data',con=self.engine)\\\n",
    "            .drop(columns=['index','Oblicz','Kup ten pojazd na ratyOblicz','Pokaż oferty z numerem VIN','Oferta od','Ma numer rejestracyjny'])\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_na_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        n_total = len(df)\n",
    "        for col in df.columns:\n",
    "            n_nulls = len(df.loc[df[col].isna()])\n",
    "            if n_nulls/n_total > 0.35:\n",
    "                df = df.drop(columns=[col])\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _drop_rows_with_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.dropna(subset=['Cena', 'Przebieg', 'Pojemność skokowa', 'Moc'])\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_to_type(x: Any, type: Union[int, float, str]) -> Union[int, float, str]:\n",
    "        try:\n",
    "            return type(x)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "    def _convert_datatypes(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['Rok produkcji'] = df['Rok produkcji'].apply(lambda x: self._convert_to_type(x, int))\n",
    "        df['Przebieg'] = df['Przebieg'].astype(str).str.replace(' km', '').str.replace(' ', '').astype(float)\n",
    "        df['Pojemność skokowa'] = df['Pojemność skokowa'].str.replace(' cm3', '').str.replace(' ', '').astype(float)\n",
    "        df['Moc'] = df['Moc'].str.replace(' KM', '').str.replace(' ', '').astype(float)\n",
    "        df['Spalanie W Mieście'] = df['Spalanie W Mieście'].str.replace(' l/100km', '').str.replace(',', '.').str.replace(' ', '').astype(float)\n",
    "        df['Liczba drzwi'] = df['Liczba drzwi'].apply(lambda x: self._convert_to_type(x, int))\n",
    "        df['Liczba miejsc'] = df['Liczba miejsc'].apply(lambda x: self._convert_to_type(x, int))\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _translate_to_eng(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        translator = Translator()\n",
    "        translator = Translator(service_urls=[\n",
    "            'translate.google.com',\n",
    "            'translate.google.pl',\n",
    "            ])\n",
    "\n",
    "        columns_to_translate = ['Rodzaj paliwa', 'Skrzynia biegów', 'Napęd', 'Typ nadwozia', 'Kolor', 'Kraj pochodzenia', 'Stan']\n",
    "        logger.info(\"Translating column contents...\")\n",
    "        for col in tqdm(columns_to_translate):\n",
    "            if col in df.columns:\n",
    "                unique_values = df[col].dropna().unique()\n",
    "                translations = {}\n",
    "                for value in unique_values:\n",
    "                    try:\n",
    "                        translations[value] = translator.translate(value).text\n",
    "                    except AttributeError:\n",
    "                        translations[value] = value\n",
    "                df[col] = df[col].map(translations)\n",
    "\n",
    "        df.columns = ['Price', 'Vehicle brand', 'Vehicle model', 'Vehicle Version', 'Vehicle Generation',\n",
    "            'Year of production', 'Mileage', 'Engine Capacity', 'Fuel Type', 'Horse Power',\n",
    "            'Transmission Type', 'Drive Type', 'Gas Usage per 100km', 'Car Body Type',\n",
    "            'Number of doors', 'Number of seats', 'Color', 'Country of origin',\n",
    "            'New/Used']\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def preprocess_data(self) -> pd.DataFrame:\n",
    "        self.df = self._remove_na_columns(self.df)\n",
    "        self.df = self._drop_rows_with_nulls(self.df)\n",
    "        self.df = self._convert_datatypes(self.df)\n",
    "        self.df = self._translate_to_eng(self.df)\n",
    "        \n",
    "        self.save_to_sql('otomoto_data_cleaned', os.getenv('DB_CONNECTION_STRING'))\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def get_data(self) -> pd.DataFrame:\n",
    "\n",
    "        self.df.columns = [\n",
    "            'price', 'vehicle_brand', 'vehicle_model', 'vehicle_version',\n",
    "            'vehicle_generation', 'year_of_production', 'mileage',\n",
    "            'engine_capacity', 'fuel_type', 'horse_power', 'transmission_type',\n",
    "            'drive_type', 'gas_usage_per_100km', 'car_body_type', 'number_of_doors',\n",
    "            'number_of_seats', 'color', 'country_of_origin', 'new_used'\n",
    "        ]\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def save_to_sql(self, table_name: str, sql_engine: str):\n",
    "        engine = create_engine(sql_engine)\n",
    "        self.df.to_sql(table_name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import datetime\n",
    "from warnings import filterwarnings\n",
    "import os\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, df, target_column):\n",
    "        self.mlflow_uri = os.getenv('MLFLOW_TRACKING_URI')\n",
    "        self.df = df\n",
    "        self.target_column = target_column\n",
    "        self.models = [('RandomForestRegressor', RandomForestRegressor()), \n",
    "                       ('XGBRegressor', XGBRegressor()), \n",
    "                       ('LGBMRegressor', LGBMRegressor())]\n",
    "        self.parameters = {'n_estimators': [50, 100, 200], \n",
    "                           'max_depth': [6, 10, 15], \n",
    "                           'min_samples_split': [2, 5, 10]}\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    def preprocess(self):\n",
    "        mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "        mlflow.set_experiment(\"otomoto_price_predictor\")\n",
    "\n",
    "        X = self.df.drop(self.target_column, axis=1)\n",
    "        y = self.df[self.target_column]\n",
    "\n",
    "        with mlflow.start_run() as encoder_run:\n",
    "            run_name = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\") \n",
    "            mlflow.set_tag(\"mlflow.runName\", run_name + '_encoder')\n",
    "            self.encoder.fit(X)\n",
    "            mlflow.sklearn.log_model(self.encoder, \"otomoto_data_encoder\")\n",
    "            mlflow.register_model(\"runs:/{}/otomoto_data_encoder\".format(mlflow.active_run().info.run_id), \"otomoto_data_encoder\")\n",
    "        mlflow.end_run()\n",
    "\n",
    "        X_encoded = self.encoder.transform(X).toarray()\n",
    "        y = y.values\n",
    "\n",
    "        self.train, self.test, self.y_train, self.y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    "        self.valid, self.test, self.y_valid, self.y_test = train_test_split(self.test, self.y_test, test_size=0.33, random_state=42)\n",
    "\n",
    "    def train_models(self):\n",
    "        mlflow.set_tracking_uri(self.mlflow_uri)\n",
    "        mlflow.set_experiment(\"otomoto_price_predictor\")\n",
    "\n",
    "        for model_name, model in self.models:\n",
    "            with mlflow.start_run() as run:\n",
    "                run_name = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")    \n",
    "                mlflow.set_tag(\"mlflow.runName\", run_name)\n",
    "\n",
    "                cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "                grid_cv = GridSearchCV(model, self.parameters, cv=cv)\n",
    "                model_name = model_name + '_otomoto_price_predictor'\n",
    "\n",
    "                grid_cv.fit(self.train, self.y_train)\n",
    "\n",
    "                for name, dataset, y_true in [('Train', self.train, self.y_train), ('Validation', self.valid, self.y_valid), ('Test', self.test, self.y_test)]:\n",
    "                    pred = grid_cv.predict(dataset)\n",
    "                    r2 = r2_score(y_true, pred)\n",
    "                    mae = mean_absolute_error(y_true, pred)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "                    mlflow.log_metric(f'{model_name} {name} R2', r2)\n",
    "                    mlflow.log_metric(f'{model_name} {name} MAE', mae)\n",
    "                    mlflow.log_metric(f'{model_name} {name} RMSE', rmse)\n",
    "\n",
    "                params = {f\"{model_name}_{k}\": v for k, v in grid_cv.best_params_.items()}\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "                model_info = mlflow.sklearn.log_model(grid_cv.best_estimator_, \"model\")\n",
    "                model_uri = \"runs:/\" + run.info.run_id + \"/\" + model_info.artifact_path\n",
    "                mlflow.register_model(model_uri, f\"{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Spalanie W Mieście'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Spalanie W Mieście'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_processor \u001b[38;5;241m=\u001b[39m Preprocessing()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m input_data \u001b[38;5;241m=\u001b[39m data_processor\u001b[38;5;241m.\u001b[39mget_data()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# model_trainer = ModelTrainer(input_data, target_column='price')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# model_trainer.preprocess()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# model_trainer.train_models()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 91\u001b[0m, in \u001b[0;36mPreprocessing.preprocess_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_na_columns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_rows_with_nulls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_datatypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_translate_to_eng(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_to_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124motomoto_data_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDB_CONNECTION_STRING\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m, in \u001b[0;36mPreprocessing._convert_datatypes\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     51\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPojemność skokowa\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPojemność skokowa\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cm3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     52\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m KM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpalanie W Mieście\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpalanie W Mieście\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m l/100km\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     54\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiczba drzwi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiczba drzwi\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_type(x, \u001b[38;5;28mint\u001b[39m))\n\u001b[0;32m     55\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiczba miejsc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiczba miejsc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_type(x, \u001b[38;5;28mint\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py310\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Spalanie W Mieście'"
     ]
    }
   ],
   "source": [
    "data_processor = Preprocessing()\n",
    "data_processor.preprocess_data()\n",
    "\n",
    "input_data = data_processor.get_data()\n",
    "\n",
    "# model_trainer = ModelTrainer(input_data, target_column='price')\n",
    "# model_trainer.preprocess()\n",
    "# model_trainer.train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model_name, transformer_name):\n",
    "        self.model_name = model_name\n",
    "        self.transformer_name = transformer_name\n",
    "        self.mlflow_client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "    def load_model(self):\n",
    "        model_version = self.mlflow_client.get_latest_versions(self.model_name)[0]\n",
    "        self.model = mlflow.sklearn.load_model(model_uri=f\"models:/{self.model_name}/{model_version.version}\")\n",
    "\n",
    "    def load_transformer(self):\n",
    "        transformer_version = self.mlflow_client.get_latest_versions(self.transformer_name)[0]\n",
    "        self.transformer = mlflow.sklearn.load_model(model_uri=f\"models:/{self.transformer_name}/{transformer_version.version}\")\n",
    "\n",
    "    def load_models(self):\n",
    "        mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))\n",
    "        mlflow.set_experiment(\"otomoto_price_predictor\")\n",
    "        self.load_model()\n",
    "        self.load_transformer()\n",
    "\n",
    "    def predict(self, data_dict):\n",
    "        data_df = pd.DataFrame([data_dict])\n",
    "        data_transformed = self.transformer.transform(data_df)\n",
    "        prediction = self.model.predict(data_transformed)\n",
    "\n",
    "        return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 34454.33975910263}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "sample_vehicle = {\n",
    "    \"model_name\": \"RandomForestRegressor_otomoto_price_predictor\",\n",
    "    \"vehicle_brand\": \"Toyota\",\n",
    "    \"vehicle_model\": \"Corolla\",\n",
    "    \"vehicle_version\": \"1.6 VVT-i\",\n",
    "    \"vehicle_generation\": \"E120\",\n",
    "    \"year_of_production\": 2005,\n",
    "    \"mileage\": 150000.0,\n",
    "    \"engine_capacity\": 1.6,\n",
    "    \"fuel_type\": \"Petrol\",\n",
    "    \"horse_power\": 110.0,\n",
    "    \"transmission_type\": \"Manual\",\n",
    "    \"drive_type\": \"FWD\",\n",
    "    \"gas_usage_per_100km\": 6.7,\n",
    "    \"car_body_type\": \"Sedan\",\n",
    "    \"number_of_doors\": 4,\n",
    "    \"number_of_seats\": 5.0,\n",
    "    \"color\": \"Silver\",\n",
    "    \"country_of_origin\": \"Japan\",\n",
    "    \"new_used\": \"Used\"\n",
    "}\n",
    "\n",
    "requests.post('http://localhost:8000/api/v1/otomoto/predict', json=sample_vehicle).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Predictor(model_name='RandomForestRegressor_otomoto_price_predictor', transformer_name='otomoto_data_encoder')\n",
    "pred.load_model()\n",
    "pred.load_transformer()\n",
    "pred.predict(sample_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_name = 'otomoto_data_encoder'\n",
    "encoder_model_version = 'latest'\n",
    "\n",
    "encoder = mlflow.sklearn.load_model(model_uri=f\"models:/{encoder_model_name}/{encoder_model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame([sample_vehicle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'DATASET LOADING AND PREPROCESSING'\n",
    "'='* 50\n",
    "\n",
    "df = pd.read_sql_table('otomoto_data',con=engine).drop(columns=['index','Oblicz','Kup ten pojazd na ratyOblicz','Pokaż oferty z numerem VIN','Oferta od','Ma numer rejestracyjny'])\n",
    "df.head()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_total = len(df)\n",
    "for col in df.columns:\n",
    "    n_nulls = len(df.loc[df[col].isna()])\n",
    "    if n_nulls/n_total > 0.35:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "def drop_rows_with_nulls(df):\n",
    "    # If any of the following columns is null, drop the row: [Cena, Przebieg, Pojemność skokowa, Moc, Spalanie W Mieście]\n",
    "    df = df.dropna(subset=['Cena', 'Przebieg', 'Pojemność skokowa', 'Moc', 'Spalanie W Mieście'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_type(x, type: int|float|str):\n",
    "    try:\n",
    "        return type(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df = drop_rows_with_nulls(df)\n",
    "\n",
    "from googletrans import Translator\n",
    "from tqdm import tqdm\n",
    "# Create a translator object\n",
    "translator = Translator()\n",
    "translator = Translator(service_urls=[\n",
    "      'translate.google.com',\n",
    "      'translate.google.pl',\n",
    "    ])\n",
    "\n",
    "columns_to_translate = ['Rodzaj paliwa', 'Skrzynia biegów', 'Napęd', 'Typ nadwozia', 'Kolor', 'Kraj pochodzenia', 'Stan']\n",
    "print(\"Translating column contents...\")\n",
    "for col in tqdm(columns_to_translate):\n",
    "    if col in df.columns:\n",
    "        unique_values = df[col].dropna().unique()\n",
    "        translations = {}\n",
    "        for value in unique_values:\n",
    "            try:\n",
    "                translations[value] = translator.translate(value).text\n",
    "            except AttributeError:\n",
    "                print(f\"Translation failed for value: {value}\")\n",
    "                translations[value] = value  # Use original value if translation fails\n",
    "        df[col] = df[col].map(translations)\n",
    "\n",
    "print(\"Translating column names...\")\n",
    "df.columns = ['Price', 'Vehicle brand', 'Vehicle model', 'Vehicle Version', 'Vehicle Generation',\n",
    "        'Year of production', 'Mileage', 'Engine Capacity', 'Fuel Type', 'Horse Power',\n",
    "        'Transmission Type', 'Drive Type', 'Gas Usage per 100km', 'Car Body Type',\n",
    "        'Number of doors', 'Number of seats', 'Color', 'Country of origin',\n",
    "        'New/Used']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'MODEL TRAINING'\n",
    "'='* 50\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import datetime\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Fit a OneHotEncoder on the original DataFrame\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(df)\n",
    "\n",
    "def make_prediction(new_data: pd.DataFrame, model):\n",
    "    # Transform the new data using the fitted encoder\n",
    "    new_data_encoded = encoder.transform(new_data)\n",
    "\n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(new_data_encoded)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Fit a OneHotEncoder on the original DataFrame\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(df)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    run_name = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\") \n",
    "    mlflow.set_tag(\"mlflow.runName\", run_name + '_encoder')\n",
    "    mlflow.sklearn.log_model(encoder, \"otomoto_data_encoder\")\n",
    "    mlflow.register_model(\"runs:/{}/otomoto_data_encoder\".format(mlflow.active_run().info.run_id), \"otomoto_data_encoder\")\n",
    "\n",
    "mlflow.end_run()\n",
    "    \n",
    "\n",
    "df_encoded = encoder.fit_transform(df).toarray()\n",
    "\n",
    "\n",
    "# 2. Train, validation and test split\n",
    "train, test = train_test_split(df_encoded, test_size=0.3, random_state=42)\n",
    "valid, test = train_test_split(test, test_size=0.33, random_state=42)\n",
    "\n",
    "# 4. Create mapping of sample parameters and do a grid search CV with KFold validation\n",
    "parameters = {'n_estimators': [50, 100, 200], 'max_depth': [6, 10, 15], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Set MLflow server\n",
    "mlflow.set_tracking_uri(\"http://10.147.18.38:31216/\")\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(\"otomoto_price_predictor\")\n",
    "\n",
    "for model_name, model in [('RandomForestRegressor', RandomForestRegressor()), ('XGBRegressor', XGBRegressor()), ('LGBMRegressor', LGBMRegressor())]:\n",
    "    with mlflow.start_run() as run:\n",
    "        # Set run name\n",
    "        run_name = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")    \n",
    "        mlflow.set_tag(\"mlflow.runName\", run_name)\n",
    "\n",
    "        cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        grid_cv = GridSearchCV(model, parameters, cv=cv)\n",
    "        model_name = model_name + '_otomoto_price_predictor'\n",
    "\n",
    "        # 5. Fit model\n",
    "        X_train, y_train = train[:, :-1], train[:, -1]\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "\n",
    "        # 6. Calculate R2, MAE, RMSE on each of those sets\n",
    "        for name, dataset in [('Train', train), ('Validation', valid), ('Test', test)]:\n",
    "            X, y = dataset[:, :-1], dataset[:, -1]\n",
    "            pred = grid_cv.predict(X)\n",
    "            r2 = r2_score(y, pred)\n",
    "            mae = mean_absolute_error(y, pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y, pred))\n",
    "            mlflow.log_metric(f'{model_name} {name} R2', r2)\n",
    "            mlflow.log_metric(f'{model_name} {name} MAE', mae)\n",
    "            mlflow.log_metric(f'{model_name} {name} RMSE', rmse)\n",
    "\n",
    "        # Log parameters\n",
    "        params = {f\"{model_name}_{k}\": v for k, v in grid_cv.best_params_.items()}\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Log model\n",
    "        model_info = mlflow.sklearn.log_model(grid_cv.best_estimator_, \"model\")\n",
    "\n",
    "        # Register model\n",
    "        model_uri = \"runs:/\" + run.info.run_id + \"/\" + model_info.artifact_path\n",
    "        mlflow.register_model(model_uri, f\"{model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "\n",
    "with mlflow.start_run():\n",
    "    run_name = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\") \n",
    "    mlflow.set_tag(\"mlflow.runName\", run_name + '_encoder')\n",
    "    mlflow.sklearn.log_model(encoder, \"Otomoto_data_encoder\")\n",
    "    mlflow.register_model(\"runs:/{}/Otomoto_data_encoder\".format(mlflow.active_run().info.run_id), \"Otomoto_data_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit_transform(df).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'PREDICTIONS'\n",
    "'='* 50\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Define the names of the registered models\n",
    "model_names = ['RandomForestRegressor', 'XGBRegressor', 'LGBMRegressor']\n",
    "task = '_otomoto_price_predictor'\n",
    "model_names = [model_name + task for model_name in model_names]\n",
    "# Initialize a dictionary to store the models\n",
    "models = {}\n",
    "\n",
    "# Load the latest version of each model\n",
    "for model_name in model_names:\n",
    "\n",
    "    model_version = client.get_latest_versions(model_name)[0]\n",
    "    models[model_name] = mlflow.sklearn.load_model(model_uri=f\"models:/{model_name}/{model_version.version}\")\n",
    "\n",
    "# Make predictions on the first row of the training set\n",
    "first_row = train[0, :-1].reshape(1, -1)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    prediction = model.predict(first_row)\n",
    "    print(f\"The prediction from {model_name} is {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "keys = ['Price', 'Vehicle brand', 'Vehicle model', 'Vehicle Version', 'Vehicle Generation',\n",
    "        'Year of production', 'Mileage', 'Engine Capacity', 'Fuel Type', 'Horse Power',\n",
    "        'Transmission Type', 'Drive Type', 'Gas Usage per 100km', 'Car Body Type',\n",
    "        'Number of doors', 'Number of seats', 'Color', 'Country of origin',\n",
    "        'New/Used']\n",
    "\n",
    "# Generate random values\n",
    "values = [random.randint(1, 100) if key == 'Price' or key == 'Year of production' or key == 'Mileage' or key == 'Horse Power' or key == 'Number of doors' or key == 'Number of seats'\n",
    "          else ''.join(random.choices(string.ascii_uppercase + string.digits, k=5)) for key in keys]\n",
    "\n",
    "# Create a dictionary\n",
    "data_dict = dict(zip(keys, values))\n",
    "\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Define the names of the registered models\n",
    "model_names = ['RandomForestRegressor', 'XGBRegressor', 'LGBMRegressor']\n",
    "task = '_otomoto_price_predictor'\n",
    "model_names = [model_name + task for model_name in model_names]\n",
    "# Initialize a dictionary to store the models\n",
    "models = {}\n",
    "\n",
    "encoder_model_name = 'otomoto_data_encoder'\n",
    "encoder_model_version = 'latest'\n",
    "\n",
    "encoder = mlflow.sklearn.load_model(model_uri=f\"models:/{encoder_model_name}/{encoder_model_version}\")\n",
    "\n",
    "input_data = encoder.transform(pd.DataFrame(data_dict, index=[0])).toarray()\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    model_version = client.get_latest_versions(model_name)[0]\n",
    "    models[model_name] = mlflow.sklearn.load_model(model_uri=f\"models:/{model_name}/{model_version.version}\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    prediction = model.predict(input_data)\n",
    "    print(f\"The prediction from {model_name} is {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
